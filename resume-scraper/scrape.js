import puppeteer from 'puppeteer';
import fs from 'fs-extra';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

(async () => {
  const inputFile = process.argv[2];

  try {
    if (!inputFile) throw new Error("‚ùå No input HTML file provided.");

    const htmlPath = path.resolve(__dirname, inputFile);
    const htmlContent = await fs.readFile(htmlPath, 'utf-8');

    const match = htmlContent.match(/https:\/\/app\.enhancv\.com\/share\/[a-zA-Z0-9]+/);
    if (!match) throw new Error("‚ùå No Enhancv URL found in HTML.");

    const resumeUrl = match[0];
    console.log(`üåê Scraping from: ${resumeUrl}`);

    const browser = await puppeteer.launch({
      args: ['--no-sandbox', '--disable-setuid-sandbox']
    });

    const page = await browser.newPage();

    console.log("üì• Navigating to Enhancv URL...");
    await page.goto(resumeUrl, {
      waitUntil: 'networkidle2', // looser than networkidle0
      timeout: 60000             // 60 seconds max wait
    });
    console.log("‚úÖ Page loaded, capturing HTML...");

    const distDir = path.resolve(__dirname, 'dist');
    await fs.ensureDir(distDir);

    const outputPath = path.join(distDir, 'JeremyLongResume.html');
    await fs.writeFile(outputPath, await page.content(), 'utf-8');

    console.log(`‚úÖ Resume saved to: ${outputPath}`);

    await browser.close();
  } catch (err) {
    console.error("‚ùå Scraper failed:", err.message);
    process.exit(1);
  }
})();
